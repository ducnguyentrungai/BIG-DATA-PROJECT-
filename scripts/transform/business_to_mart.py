from pyspark.sql import SparkSession
from pyspark.sql.functions import col, year, month, avg, sum
import os

# def transform_business_to_mart(business_path: str, mart_output_path: str):
#     """
#     Chuyá»ƒn dá»¯ liá»‡u tá»« táº§ng Business sang táº§ng Mart:
#     - Tá»•ng há»£p theo thÃ¡ng
#     - TÃ­nh trung bÃ¬nh giÃ¡ Open, High, Low, Close
#     - TÃ­nh tá»•ng khá»‘i lÆ°á»£ng giao dá»‹ch (Total_Volume)
#     """

#     spark = SparkSession.builder.appName("BusinessToMartStockETL").getOrCreate()

#     try:
#         abs_business = os.path.abspath(business_path)
#         abs_mart = os.path.abspath(mart_output_path)

#         if not os.path.exists(abs_business):
#             raise FileNotFoundError(f"âŒ KhÃ´ng tÃ¬m tháº¥y dá»¯ liá»‡u Business táº¡i: {abs_business}")
#         print(f"ğŸ“¥ Äang Ä‘á»c dá»¯ liá»‡u Business tá»«: {abs_business}")

#         df = spark.read.parquet(abs_business)
#         original_count = df.count()
#         print(f"ğŸ”¢ Sá»‘ dÃ²ng ban Ä‘áº§u: {original_count}")

#         if original_count == 0:
#             raise ValueError("âŒ Dá»¯ liá»‡u Business rá»—ng.")

#         # Kiá»ƒm tra schema báº¯t buá»™c
#         required_columns = {"Date", "Open", "High", "Low", "Close", "Volume"}
#         missing = required_columns - set(df.columns)
#         if missing:
#             raise ValueError(f"âŒ Thiáº¿u cÃ¡c cá»™t báº¯t buá»™c trong Business: {missing}")

#         # LÃ m sáº¡ch dá»¯ liá»‡u
#         df = df.dropna(subset=["Date", "Open", "High", "Low", "Close", "Volume"])
#         df = df.filter(
#             (col("Open") >= 0) &
#             (col("High") >= 0) &
#             (col("Low") >= 0) &
#             (col("Close") >= 0) &
#             (col("Volume") >= 0)
#         )

#         cleaned_count = df.count()
#         print(f"âœ… Sau lÃ m sáº¡ch: {cleaned_count} dÃ²ng (máº¥t {original_count - cleaned_count} dÃ²ng)")

#         # ThÃªm cá»™t Year/Month náº¿u chÆ°a cÃ³
#         if "Year" not in df.columns or "Month" not in df.columns:
#             df = df \
#                 .withColumn("Year", year(col("Date"))) \
#                 .withColumn("Month", month(col("Date")))

#         # Tá»•ng há»£p theo thÃ¡ng
#         df_monthly = df.groupBy("Year", "Month").agg(
#             avg("Open").alias("Average_Open"),
#             avg("High").alias("Average_High"),
#             avg("Low").alias("Average_Low"),
#             avg("Close").alias("Average_Close"),
#             sum("Volume").alias("Total_Volume")
#         ).orderBy("Year", "Month")

#         print("ğŸ“Š Dá»¯ liá»‡u Mart (Monthly Summary):")
#         df_monthly.show(10)

#         # Ghi xuá»‘ng táº§ng Mart
#         df_monthly.write.mode("overwrite").parquet(abs_mart)
#         print(f"ğŸ’¾ ÄÃ£ ghi dá»¯ liá»‡u Mart vÃ o: {abs_mart}")

#     except Exception as e:
#         print(f"âŒ Lá»—i Business â†’ Mart: {e}")

#     finally:
#         spark.stop()


def transform_business_to_mart(business_path: str, mart_output_path: str):
    """
    Chuyá»ƒn dá»¯ liá»‡u tá»« táº§ng Business sang táº§ng Mart:
    - Tá»•ng há»£p theo thÃ¡ng
    - TÃ­nh trung bÃ¬nh giÃ¡ Ä‘Ã³ng cá»­a (Average_Close)
    - TÃ­nh tá»•ng khá»‘i lÆ°á»£ng giao dá»‹ch (Total_Volume)
    """

    spark = SparkSession.builder.appName("BusinessToMartStockETL").getOrCreate()

    try:
        abs_business = os.path.abspath(business_path)
        abs_mart = os.path.abspath(mart_output_path)

        if not os.path.exists(abs_business):
            raise FileNotFoundError(f"âŒ KhÃ´ng tÃ¬m tháº¥y dá»¯ liá»‡u Business táº¡i: {abs_business}")
        print(f"ğŸ“¥ Äang Ä‘á»c dá»¯ liá»‡u Business tá»«: {abs_business}")

        df = spark.read.parquet(abs_business)
        original_count = df.count()
        print(f"ğŸ”¢ Sá»‘ dÃ²ng ban Ä‘áº§u: {original_count}")

        if original_count == 0:
            raise ValueError("âŒ Dá»¯ liá»‡u Business rá»—ng.")

        # Kiá»ƒm tra schema báº¯t buá»™c
        required_columns = {"Date", "Close", "Volume"}
        missing = required_columns - set(df.columns)
        if missing:
            raise ValueError(f"âŒ Thiáº¿u cÃ¡c cá»™t báº¯t buá»™c trong Business: {missing}")

        # Loáº¡i bá» dÃ²ng thiáº¿u dá»¯ liá»‡u quan trá»ng
        df = df.dropna(subset=["Date", "Close", "Volume"])
        df = df.filter((col("Close") >= 0) & (col("Volume") >= 0))

        cleaned_count = df.count()
        print(f"âœ… Sau lÃ m sáº¡ch: {cleaned_count} dÃ²ng (máº¥t {original_count - cleaned_count} dÃ²ng)")

        # ThÃªm cá»™t Year/Month náº¿u chÆ°a cÃ³ (trÃ¡nh overwrite náº¿u Ä‘Ã£ cÃ³ sáºµn)
        if "Year" not in df.columns or "Month" not in df.columns:
            df = df \
                .withColumn("Year", year(col("Date"))) \
                .withColumn("Month", month(col("Date")))

        # Tá»•ng há»£p theo thÃ¡ng
        df_monthly = df.groupBy("Year", "Month").agg(
            avg("Close").alias("Average_Close"),
            sum("Volume").alias("Total_Volume")
        ).orderBy("Year", "Month")

        print("ğŸ“Š Dá»¯ liá»‡u Mart (Monthly Summary):")
        df_monthly.show(10)

        # Ghi xuá»‘ng táº§ng Mart
        df_monthly.write.mode("overwrite").parquet(abs_mart)
        print(f"ğŸ’¾ ÄÃ£ ghi dá»¯ liá»‡u Mart vÃ o: {abs_mart}")

    except Exception as e:
        print(f"âŒ Lá»—i Business â†’ Mart: {e}")

    finally:
        spark.stop()
