from pyspark.sql import SparkSession
from pyspark.sql.functions import col, to_date
import os

def transform_core_to_business(core_path: str, business_path: str):
    spark = SparkSession.builder \
        .appName("CoreToBusinessStockETL") \
        .getOrCreate()
    
    try:
        if not os.path.exists(core_path):
            raise FileNotFoundError(f"‚ùå Kh√¥ng t√¨m th·∫•y th∆∞ m·ª•c core: {core_path}")
        
        print(f"üì• ƒê·ªçc d·ªØ li·ªáu t·ª´ core: {core_path}")
        df_core = spark.read.parquet(core_path)

        if df_core.count() == 0:
            raise ValueError("‚ùå D·ªØ li·ªáu core r·ªóng.")

        # Chuy·ªÉn ƒë·ªïi ng√†y n·∫øu c·∫ßn
        df_core = df_core.withColumn("Date", to_date(col("Date")))

        # T·ªïng h·ª£p theo ng√†y
        df_business = df_core.groupBy("Date").agg(
            {"Open": "first", "High": "max", "Low": "min", "Close": "last", "Volume": "sum"}
        ).orderBy("Date")

        # Ghi xu·ªëng Business
        df_business.write.mode("overwrite").parquet(business_path)
        print(f"‚úÖ Business data written to: {business_path}")

        return df_business

    except Exception as e:
        print(f"‚ùå L·ªói trong Core ‚Üí Business: {e}")
    finally:
        spark.stop()
